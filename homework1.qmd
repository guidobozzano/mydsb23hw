---
title: "Homerwork 1"
author: "GUIDO BOZZANO"
date: 2023-05-14
format: 
  docx: default
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)
library(nycflights13)
library(skimr)

```

# Data Manipulation

## Problem 1: Use logical operators to find flights that:

```         
-   Had an arrival delay of two or more hours (\> 120 minutes)
-   Flew to Houston (IAH or HOU)
-   Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
-   Departed in summer (July, August, and September)
-   Arrived more than two hours late, but didn't leave late
-   Were delayed by at least an hour, but made up over 30 minutes in flight
```

```{r}
#| label: problem-1

# Had an arrival delay of two or more hours (> 120 minutes)
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to the arr_delay variable of >120 minutes
flights %>% 
  filter(arr_delay >= 120)
  
# Flew to Houston (IAH or HOU)
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to the dest variable to look for destination Houston (IAH or HOU)
  filter(flights, dest == "IAH"| dest == "HOU") 

# Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to the carrier variable to look for flights from United, American and Delta
  filter(flights, carrier == "UA"| carrier == "AA" | carrier == "DL") 

# Departed in summer (July, August, and September)
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to the carrier month variable to look for flights departed in the summer months
  filter(flights, month == 7 | month == 8 | month == 9)  
  
# Arrived more than two hours late, but didn't leave late
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to the arr_delay to indicate more than 120 minutes of delay but the departure delay is below 0
  filter(flights, arr_delay >=120 , dep_delay <=0) 

# Were delayed by at least an hour, but made up over 30 minutes in flight
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to the arr_delay to indicate that they arrived less than 30 minutes and the departure delay was at least 60 minutes
  filter(flights, arr_delay <30 , dep_delay >=60)   
```

## Problem 2: What months had the highest and lowest proportion of cancelled flights? Interpret any seasonal patterns. To determine if a flight was cancelled use the following code

<!-- -->

```         
flights %>% 
  filter(is.na(dep_time)) 
```

```{r}
#| label: problem-2

# What months had the highest and lowest % of cancelled flights?
#For this problem I begin using the flights table included in the nycflights13 and apply a filter to understand how many flights were cancelled (is.na(dep_time)). Then, I group by month and then I count per month and mutate a new column to understand the proportion of each month
flights %>%
  filter(is.na(dep_time)) %>% 
  group_by (month) %>% 
  summarise(count = n()) %>% 
  mutate(prop = count/sum(count))
 
#Answer: Highest is February with 15.2% and lowest is November with 2.8%

```

## Problem 3: What plane (specified by the `tailnum` variable) traveled the most times from New York City airports in 2013? Please `left_join()` the resulting table with the table `planes` (also included in the `nycflights13` package).

For the plane with the greatest number of flights and that had more than 50 seats, please create a table where it flew to during 2013.

```{r}
#For this problem I create a new table called mostflights based on the flights table included in the nycflights13 and apply a filter to the year equal to 2013. Also, I apply a filter to bring me the results of those observations in which I have a tailnum.
#Afterwards, I group by tailnum and origin and count the number of flights (When I ran the code without the .groups= "drop" I had a warning, thus I included that piece of code inside the summarise). Last, I arrange in descending order
#This table I created counts me the flights by tailnum and origin
mostflights <- flights %>%
  filter(year == 2013) %>% 
  filter(!is.na(tailnum)) %>% 
  group_by(tailnum,origin) %>% 
  summarise(total_flights=n(), .groups = "drop") %>% 
  arrange(desc(total_flights))
mostflights

#Now I do a left_join between the table defined above - mostflights - and planes by "tailnum". Also, I make sure to exclude the N/A matches by applying na_matches = "never" in the left_join.
#Then I apply the seats > 50 filter to understand which planes have the most number of flights and have seats > 50. I save this under a new object called answer
answer <- left_join(mostflights, planes, by="tailnum", na_matches = "never") %>% 
  filter(seats>50)
answer

#Finally, I look for the tailnum that the answer table give me as the most flights and apply that information to filter the flights table.
#I create a new object called table_answer where I apply this filter and count the number of flights the "N328AA" tailnum did by destination
table_answer <- flights %>% 
  filter(tailnum=="N328AA") %>% 
  group_by(tailnum,dest) %>% 
  summarise(total_flights=n(), .groups="drop") %>% 
  arrange(desc(total_flights))
table_answer

```

## Problem 4: The `nycflights13` package includes a table (`weather`) that describes the weather during 2013. Use that table to answer the following questions:

```         
-   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
-   What is the relationship between `dewp` and `humid`?
-   What is the relationship between `precip` and `visib`?
```

```{r}
#Based on the weather table, I create a new object called july13 which filters the weather table by year == 2013 and month == 7
july13 <- weather %>%
  filter(year==2013,month==7)
  
#To understand the temperature distribution I do a histogram using ggplot and geom_histogram and the july13 table defined above and map the x variable as "temp". I set the title using labels (labs function)

ggplot(july13, aes(x=temp)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Temperature Distribution")

#To understand the wind speed distribution I do a histogram using ggplot and geom_histogram and the july13 table defined above and map the x variable as "wind_speed". I set the title using labels (labs function)

ggplot(july13, aes(x=wind_speed)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Windspeed Distribution")

#Answer 2: Based on the wind speed distribution I can observe outliers when the wind speed is exactly 11 as there are no observations with that information. The same happens when the wind speed is 1 or 2.

#To understand relationships between two variables I plot a scatter plot using geom_point and also calculate the correlation between the two variables for a clear indication of the relationship. To do so, I use the table july13 and apply a summarise with the cor function to the variables dewp and humid

ggplot(weather, aes(x=dewp, y=humid)) +
  geom_point() +
  labs(title = "Relationship between Dewp and Humid variables")

weather %>% 
  summarise(corr_dh=cor(dewp,humid, use="complete.obs"))

#Answer 3: There seems to be a positive relationship between humidity and dew point temperature since the coefficient of correlation is 0.52. Therefore, as the humidity in the air increases the dew point temperature also increases

#To understand relationships between two variables I plot a scatter plot using geom_point and also calculate the correlation between the two variables for a clear indication of the relationship. To do so, I use the table july13 and apply a summarise with the cor function to the variables precip and visib

ggplot(weather, aes(x=precip, y=visib)) +
  geom_point() +
  labs(title = "Relationship between Precip and Visib variables")

weather %>% 
  summarise(corr_pv=cor(precip,visib, use="complete.obs"))

#Answer 4:On the other hand the relationship between visibility and precipitation is not that clear as the coefficient of correlation is -0.32. This indicates that there is not clear linear relationship between the precip and visib variables

```

## Problem 5: Use the `flights` and `planes` tables to answer the following questions:

```         
-   How many planes have a missing date of manufacture?
-   What are the five most common manufacturers?
-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)
```

```{r}
#To answer the first question I begin by using the planes table, then group it by year and filter which years have missing values (i.e: N/As). Then I count them to find how many there are
planes %>% 
  group_by(year) %>% 
  filter(is.na(year)) %>% 
  summarise(total_na=n())

#Answer: There are 70 planes with missing date of manufacture

#For the second question I also use the planes table and group them by manufacturer. Then, I create a new variable called total_manuf that counts the amount of manufacturers there are in the table and arrange them in descending order. Last, I select the top 5 total manufacturers 
planes %>% 
  group_by(manufacturer) %>% 
  summarise(total_manuf=n()) %>% 
  arrange(desc(total_manuf)) %>% 
  top_n(5,total_manuf)

#To answer the third question I begin by creating a table called flights_subset that contains the origin NYC and year equal to 2013.
flights_subset <- filter(flights, year == 2013, origin %in% c("JFK", "LGA", "EWR"))

#Then I do a left join between the table before and planes by tailnum. Then I mutate the manufacturer column and apply a case when to collapse the multiple AIRBUS manufacturers into 1 and then case when to group the others
answer <- left_join(flights_subset, planes, by="tailnum", na_matches = "never") %>% 
  mutate(manufacturer = case_when(
    manufacturer %in% c("AIRBUS INDUSTRIE", "AIRBUS") ~ "AIRBUS", # Keep Boeing and Airbus as they are
    manufacturer %in% c("BOEING", "EMBRAER", "BOMBARDIER INC") ~ manufacturer,
    TRUE ~ "Other"  # Collapse other manufacturers into "Other" category
  ))
answer

#Then I define a manufacturers over time table and group it by month and manufacturer and count
manufacturers_over_time <- answer %>%
  group_by(month,manufacturer) %>%
  summarise(count = n())

manufacturers_over_time

#Last I plot the distribution of manufacturers over time for the year 2013 using ggplot
ggplot(manufacturers_over_time, aes(x = month, y = count, fill = manufacturer)) + #Set up x as month and y as the count where the colour fill is the manufacturer
  geom_bar(stat = "identity", position = "fill") + #Set up the chart as a bar chart
  labs(title = "Distribution of Manufacturers over Time",
       x = "Month",
       y = "Count",
       fill = "Manufacturer") +
  theme_minimal()

#From the chart I can conclude that the distribution of manufacturers hasn't changed much in the year 2013 for planes departing NYC

```

## Problem 6: Use the `flights` and `planes` tables to answer the following questions:

```         
-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
-   How many airplanes that flew from New York City are included in the planes table?
```

```{r}
#First I filter the flights from NYC airports in 2013
nyc_flights_2013 <- flights %>%
  filter(year == 2013)

#Then I make sure to join with planes table to get the aircraft details
flights_with_planes <- left_join(nyc_flights_2013, planes %>% 
                                   rename(year_plane = year), by = "tailnum")

#Find the oldest plane
oldest_plane <- flights_with_planes %>%
  filter(!is.na(year_plane)) %>%
  arrange(year_plane) %>%
  select(tailnum, year_plane) %>%
  slice(1)

oldest_plane #Display the oldest plane

flightsnyc <- flights %>% #Define a flights from NYC table
  filter(origin %in% c("JFK", "LGA", "EWR")) #Only contains NYC origins

answer <- flightsnyc %>% 
  inner_join(planes, by = "tailnum") %>% #Create an innerjoin with the planes table by tailnum
  distinct(tailnum) %>% 
  summarise(count=n())

answer #Display the result

#Answer A: N381AA - 1956
#Answer B: 3322

```

## Problem 7: Use the `nycflights13` to answer the following questions:

```         
-   What is the median arrival delay on a month-by-month basis in each airport?
-   For each airline, plot the median arrival delay for each month and origin airport.
```

```{r}

#First I define a new table called arrivdelay that groups by month and destination, then I calculate the median arrival delay excluding N/As
arrivdelay <- flights %>% 
  group_by(month,dest) %>% 
  summarise(med_arrdelay = median(arr_delay, na.rm = TRUE))

arrivdelay #Display the results

#First I define a new table called arrivdelay that groups by month, origin and carrier, then I calculate the median arrival delay excluding N/As. After this I use ggplot to make a boxplot chart facet wrapped by carrier with the x-axis equal to month and y equal to med_arrdelay
arrivd <- flights %>% 
  group_by(month,origin,carrier) %>% 
  summarise(med_arrdelay = median(arr_delay, na.rm = TRUE))

ggplot(arrivd, aes(x=month, y=med_arrdelay, fill=origin)) +
  geom_boxplot() +
  facet_wrap(vars(carrier)) +
  labs(title="Median Arrival Delay per month and Origin Airport by Airline")

```

## Problem 8: Let's take a closer look at what carriers service the route to San Francisco International (SFO). Join the `flights` and `airlines` tables and count which airlines flew the most to SFO. Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

```{r}
#First, I carry out a leftjoin between the flights and airlines table by tailnum. I filter destination SFO and group by name. Then, I count and mutate a new column to find the percent trips that each airline flew to SFO
fly_into_sfo <- left_join(flights,airlines, by="carrier") %>% 
  filter(dest=="SFO") %>% 
  group_by (name) %>% 
  summarise(count = n()) %>% 
  mutate(percent = round(count/sum(count),4)*100)
  
fly_into_sfo #Display the results
```

And here is some bonus ggplot code to plot your dataframe

```{r}
#| label: ggplot-flights-toSFO
#| message: false
#| warning: false

fly_into_sfo %>% 
  
  # sort 'name' of airline by the numbers it times to flew to SFO
  mutate(name = fct_reorder(name, count)) %>% 
  
  ggplot() +
  
  aes(x = count, 
      y = name) +
  
  # a simple bar/column plot
  geom_col() +
  
  # add labels, so each bar shows the % of total flights 
  geom_text(aes(label = percent),
             hjust = 1, 
             colour = "white", 
             size = 5)+
  
  # add labels to help our audience  
  labs(title="Which airline dominates the NYC to SFO route?", 
       subtitle = "as % of total flights in 2013",
       x= "Number of flights",
       y= NULL) +
  
  theme_minimal() + 
  
  # change the theme-- i just googled those , but you can use the ggThemeAssist add-in
  # https://cran.r-project.org/web/packages/ggThemeAssist/index.html
  
  theme(#
    # so title is left-aligned
    plot.title.position = "plot",
    
    # text in axes appears larger        
    axis.text = element_text(size=12),
    
    # title text is bigger
    plot.title = element_text(size=18)
      ) +

  # add one final layer of NULL, so if you comment out any lines
  # you never end up with a hanging `+` that awaits another ggplot layer
  NULL
 
 
```

## Problem 9: Let's take a look at cancellations of flights to SFO. We create a new dataframe `cancellations` as follows

```{r}

cancellations <- flights %>% 
  
  # just filter for destination == 'SFO'
  filter(dest == 'SFO') %>% 
  
  # a cancelled flight is one with no `dep_time` 
  filter(is.na(dep_time))

```

I want you to think how we would organise our data manipulation to create the following plot. No need to write the code, just explain in words how you would go about it.

![](images/sfo-cancellations.png)

To make a graph that looks like the one above I believe I should create a ggplot with a geom_bar that facet wraps by origin and carrier. The sub plot per each wrap would be number of cancellations (y-axis) by month (x-axis)

## Problem 10: On your own -- Hollywood Age Gap

The website https://hollywoodagegap.com is a record of *THE AGE DIFFERENCE IN YEARS BETWEEN MOVIE LOVE INTERESTS*. This is an informational site showing the age gap between movie love interests and the data follows certain rules:

-   The two (or more) actors play actual love interests (not just friends, coworkers, or some other non-romantic type of relationship)
-   The youngest of the two actors is at least 17 years old
-   No animated characters

The age gaps dataset includes "gender" columns, which always contain the values "man" or "woman". These values appear to indicate how the characters in each film identify and some of these values do not match how the actor identifies. We apologize if any characters are misgendered in the data!

The following is a data dictionary of the variables used

| variable            | class     | description                                                                                             |
|:------------------|:------------------|:---------------------------------|
| movie_name          | character | Name of the film                                                                                        |
| release_year        | integer   | Release year                                                                                            |
| director            | character | Director of the film                                                                                    |
| age_difference      | integer   | Age difference between the characters in whole years                                                    |
| couple_number       | integer   | An identifier for the couple in case multiple couples are listed for this film                          |
| actor_1\_name       | character | The name of the older actor in this couple                                                              |
| actor_2\_name       | character | The name of the younger actor in this couple                                                            |
| character_1\_gender | character | The gender of the older character, as identified by the person who submitted the data for this couple   |
| character_2\_gender | character | The gender of the younger character, as identified by the person who submitted the data for this couple |
| actor_1\_birthdate  | date      | The birthdate of the older member of the couple                                                         |
| actor_2\_birthdate  | date      | The birthdate of the younger member of the couple                                                       |
| actor_1\_age        | integer   | The age of the older actor when the film was released                                                   |
| actor_2\_age        | integer   | The age of the younger actor when the film was released                                                 |

```{r}

age_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')

#To understand the age difference distribution I use age_gaps to make a graph using ggplot. I make sure to apply geom_histogram to make a histogram to understand the distribution
ggplot(age_gaps, aes(x=age_difference)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Age Difference Distribution")

#Also, to understand what's the typical median age_difference I calculate the median value for the age_difference
age_gaps %>% 
  summarise(median_agedif=median(age_difference))

#Answer A: From the chart I can conclude that the age difference is particularly skewed towards the lower end of the difference. In addition, from the medican calculation I know that the median age difference from the age_gaps dataset is 8 which is in line with what the graph displays

#To calculate the half plus seven rule I define a new table called agegapdata that has the upper and lower bounds mutate with the information provided by the formula

#Then, I calculate the lower and upper age bounds based on the "half plus seven" rule
agegapdata <- age_gaps %>%
  mutate(lower_bound = floor(actor_1_age/2) + 7,
         upper_bound = (actor_1_age - 7) * 2)

#Afterwards, I make sure to count the number of actor/actress pairs that satisfy the "half plus seven" rule
rule_applies <- agegapdata %>%
  filter(actor_2_age >= lower_bound, actor_2_age <= upper_bound) %>%
  tally()

#Last, I calculate the percentage of pairs that satisfy the rule
percentage_rule_applies <- rule_applies$n / nrow(agegapdata) * 100

percentage_rule_applies #To show the results
#Answer is around 74% (74.02597)

#To understand how many couples each movie has I make a group by movie_name to the age_gaps table I count them and arrange them descendingly
age_gaps %>% 
  group_by(movie_name) %>% 
  summarise(count=n()) %>% 
  arrange(desc(count))

#Answer is Love Actually with 7

#To understand which actors have the greatest number of love interests in each movie I summarise by actor_1_name and actor_2_name and then I define a new variable called loveint to count the distinct number of couples. Last I arrange them by descending order
age_gaps %>% 
  group_by(actor_1_name) %>% 
  summarise(lovint=n_distinct(couple_number)) %>% 
  arrange(desc(lovint))

age_gaps %>% 
  group_by(actor_2_name) %>% 
  summarise(lovint=n_distinct(couple_number)) %>% 
  arrange(desc(lovint))

#Answer Pierce Brosnan for the male actors and Diane Keaton for the female actors

#To understand whether the age difference varies over time I create a new table called agedifplot which groups the data by release_year and calculate the mean in agedifference. Afterwards I plot the information in a line chart using ggplot + geom_line.
#From the graph I can conclude the age difference has varied significantly over time and does not stay constant
agedifplot <- age_gaps %>% 
  group_by(release_year) %>% 
  summarise(avgagedif=mean(age_difference)) 

ggplot(agedifplot,aes(x=release_year,y=avgagedif)) +
  geom_line() +
  labs(title = "Average Age Difference over time")

#To find the number of movies with same gender love relationships I create a table called same_gender and filter the information by how many characters gender are equal between 1 and 2 actors. Last, I count the information
same_gender <- age_gaps %>% 
  filter(character_1_gender==character_2_gender) %>% 
  summarise(count=n())

same_gender
#Answer: There are 23 movies that display same gender love relationships in the age_gaps dataset
```

How would you explore this data set? Here are some ideas of tables/ graphs to help you with your analysis

-   How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

-   The `half plus seven\` rule. Large age disparities in relationships carry certain stigmas. One popular rule of thumb is the [half-your-age-plus-seven](https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships#The_.22half-your-age-plus-seven.22_rule) rule. This rule states you should never date anyone under half your age plus seven, establishing a minimum boundary on whom one can date. In order for a dating relationship to be acceptable under this rule, your partner's age must be:

$$\frac{\text{Your age}}{2} + 7 < \text{Partner Age} < (\text{Your age} - 7) * 2$$ How frequently does this rule apply in this dataset?

-   Which movie has the greatest number of love interests?
-   Which actors/ actresses have the greatest number of love interests in this dataset?
-   Is the mean/median age difference staying constant over the years (1935 - 2022)?
-   How frequently does Hollywood depict same-gender love interests?

# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Render the edited and completed Quarto Markdown (qmd) file as a Word document (use the "Render" button at the top of the script editor window) and upload it to Canvas. You must be commiting and pushing tour changes to your own Github repo as you go along.

# Details

-   Who did you collaborate with: IGNACIO GAING
-   Approximately how much time did you spend on this problem set: 10 hours or more
-   What, if anything, gave you the most trouble: From problem 3 onwards, specially problem 10

**Please seek out help when you need it,** and remember the [15-minute rule](https://mam2022.netlify.app/syllabus/#the-15-minute-rule){target="_blank"}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?

# Rubric

13/13: Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output. Multiple Github commits. Work is exceptional. I will not assign these often.

8/13: Problem set is 60--80% complete and most answers are correct. This is the expected level of performance. Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). A few Github commits.

5/13: Problem set is less than 60% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often. Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No Github commits.
